import pyaudio
import wave
from http import HTTPStatus
import asyncio
import os
from openai import OpenAI
from dashscope.audio.asr import Recognition
import dashscope
import time
from commit import _run_demo
from memory import MemoryManager
from vad_tool import WebRTCVADRecorder, RealTimeVoiceMonitor
from config import Config

class ElderlyCompanionDemo:
    def __init__(self):
        # åˆå§‹åŒ–å®¢æˆ·ç«¯
        self.setup_clients()

        # éŸ³é¢‘å‚æ•°
        self.chunk = 1024
        self.format = pyaudio.paInt16
        self.channels = 1
        self.rate = 16000
        self.record_seconds = 5  # æ¯æ¬¡å½•éŸ³æ—¶é•¿

    def setup_clients(self):
        """åˆå§‹åŒ–é˜¿é‡Œäº‘å„æœåŠ¡å®¢æˆ·ç«¯"""
        # è°ƒç”¨ç™¾ç‚¼API
        self.client = OpenAI(
            # è‹¥æ²¡æœ‰é…ç½®ç¯å¢ƒå˜é‡ï¼Œè¯·ç”¨ç™¾ç‚¼API Keyå°†ä¸‹è¡Œæ›¿æ¢ä¸ºï¼šapi_key="sk-xxx",
            api_key=Config.API_KEY,
            base_url=Config.BASE_URL,
        )

    def record_audio(self, filename="user_audio.wav"):
        """å½•åˆ¶éŸ³é¢‘ - æ™ºèƒ½åœé¡¿"""
        filename = WebRTCVADRecorder().record_until_silence()
        return filename

    def record_audio1(self, filename="user_audio.wav"):
        """å½•åˆ¶éŸ³é¢‘ - å›ºå®šæ—¶é•¿ä¸º self.record_seconds ç§’"""
        try:
            p = pyaudio.PyAudio()

            stream = p.open(
                format=self.format,
                channels=self.channels,
                rate=self.rate,
                input=True,
                frames_per_buffer=self.chunk,
                input_device_index=1
            )

            print(f"å¼€å§‹å½•éŸ³...ï¼ˆ{self.record_seconds}ç§’ï¼‰")
            frames = []

            total_frames = int(self.rate * self.record_seconds / self.chunk)
            # print(f"é¢„è®¡å½•åˆ¶å¸§æ•°: {total_frames}")

            for i in range(total_frames):
                try:
                    data = stream.read(self.chunk, exception_on_overflow=False)
                    frames.append(data)
                    # æ˜¾ç¤ºå½•éŸ³è¿›åº¦
                    # if i % 10 == 0:  # æ¯10å¸§æ‰“å°ä¸€æ¬¡è¿›åº¦
                    #     print(f"å½•åˆ¶è¿›åº¦: {i + 1}/{total_frames}")
                except Exception as e:
                    print(f"è¯»å–éŸ³é¢‘æ•°æ®æ—¶å‡ºé”™: {e}")
                    break

            print(f"å½•éŸ³ç»“æŸï¼Œå…±å½•åˆ¶ {len(frames)} å¸§æ•°æ®")

            stream.stop_stream()
            stream.close()
            p.terminate()

            # æ£€æŸ¥æ•°æ®
            if not frames:
                print("è­¦å‘Šï¼šæ²¡æœ‰å½•åˆ¶åˆ°ä»»ä½•éŸ³é¢‘æ•°æ®")
                return False

            # ä¿å­˜ä¸ºwavæ–‡ä»¶
            wf = wave.open(filename, 'wb')
            wf.setnchannels(self.channels)
            wf.setsampwidth(p.get_sample_size(self.format))
            wf.setframerate(self.rate)
            wf.writeframes(b''.join(frames))
            wf.close()

            file_size = os.path.getsize(filename)
            print(f"éŸ³é¢‘æ–‡ä»¶å·²ä¿å­˜: {filename}, å¤§å°: {file_size} å­—èŠ‚")

            # éªŒè¯æ–‡ä»¶æ˜¯å¦å¯ä»¥æ­£å¸¸è¯»å–
            try:
                test_wf = wave.open(filename, 'rb')
                test_frames = test_wf.getnframes()
                test_rate = test_wf.getframerate()
                test_wf.close()
                print(f"æ–‡ä»¶éªŒè¯: {test_frames} å¸§, é‡‡æ ·ç‡: {test_rate} Hz")
            except Exception as e:
                print(f"æ–‡ä»¶éªŒè¯å¤±è´¥: {e}")
                return False

            return filename

        except Exception as e:
            print(f"å½•éŸ³è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
            return None

    def speech_to_text(self, audio_file="user_audio.wav"):
        """è¯­éŸ³è½¬æ–‡æœ¬ - ä½¿ç”¨æ–‡ä»¶è½¬å†™æœåŠ¡"""
        try:
            dashscope.api_key = os.getenv("DASHSCOPE_API_KEY")
            recognition = Recognition(model='fun-asr-realtime',
                                      format='wav',
                                      sample_rate=16000,
                                      callback=None)
            result = recognition.call(audio_file)
            if result.status_code != HTTPStatus.OK:
                print('Error: ', result.message)
                return ""
            # print('\nè¯­éŸ³è½¬æ–‡æœ¬è¯†åˆ«ç»“æœï¼š')
            # print(result.get_sentence())
            # print(
            #     '[Metric] requestId: {}, first package delay ms: {}, last package delay ms: {}'
            #     .format(
            #         recognition.get_last_request_id(),
            #         recognition.get_first_package_delay(),
            #         recognition.get_last_package_delay(),
            #     ))
            resp = result.get_sentence()
            if len(resp) > 0:
                return resp[0]['text']
            else:
                return ""
        except Exception as e:
            print(f"è¯­éŸ³è¯†åˆ«é”™è¯¯: {e}")
            return ""

    def text_to_speech(self, text, audio_name="response_audio.wav"):
        """æ–‡æœ¬è½¬è¯­éŸ³"""
        try:
            save_file = asyncio.run(_run_demo(text, audio_name))
            return save_file

        except Exception as e:
            print(f"è¯­éŸ³åˆæˆé”™è¯¯: {e}")
            return None

    def play_audio(self, audio_file):
        """æ’­æ”¾éŸ³é¢‘"""
        try:
            wf = wave.open(audio_file, 'rb')
            p = pyaudio.PyAudio()

            stream = p.open(format=p.get_format_from_width(wf.getsampwidth()),
                            channels=wf.getnchannels(),
                            rate=wf.getframerate(),
                            output=True)

            data = wf.readframes(self.chunk)
            while data:
                stream.write(data)
                data = wf.readframes(self.chunk)

            stream.stop_stream()
            stream.close()
            p.terminate()
            wf.close()

        except Exception as e:
            print(f"æ’­æ”¾éŸ³é¢‘é”™è¯¯: {e}")

    def call_bailian_api(self, memory_context, user_input):
        """è°ƒç”¨ç™¾ç‚¼å¤§æ¨¡å‹API"""
        try:
            completion = self.client.chat.completions.create(
                # æ¨¡å‹åˆ—è¡¨ï¼šhttps://help.aliyun.com/zh/model-studio/getting-started/models
                # model="qwen-plus",
                model="qwen-max",
                messages=[
                    {"role": "system", "content": f"ä½ æ˜¯ä¸€ä¸ªä¸“é—¨ä¸ºè€å¹´äººè®¾è®¡çš„é™ªä¼´æœºå™¨äººï¼Œåå­—å«å°ä¼´ã€‚ä½ è¯´è¯è¦æ¸©æŸ”ã€è€å¿ƒã€ç®€æ´ï¼Œè¯­é€Ÿè¦æ…¢ä¸€ç‚¹, {memory_context}, "
                                                  f"ç»å¯¹ç¦æ­¢åœ¨å›å¤ä¸­ä½¿ç”¨ä»»ä½•å½¢å¼çš„è¡¨æƒ…ç¬¦å·ã€é¢œæ–‡å­—ï¼ˆä¾‹å¦‚ï¼šğŸ˜€, ğŸ˜Š, :) , :( ç­‰ï¼‰ã€‚"
                                                  f"å›å¤å†…å®¹åº”ä¿æŒæ­£å¼ã€ä¹¦é¢åŒ–çš„è¯­è¨€é£æ ¼ï¼Œç¡®ä¿è¾“å‡ºä¸ºçº¯å‡€çš„ä¸­æ–‡æ–‡æœ¬å†…å®¹ã€‚"
                                                  f"ä½ æ‰€æœ‰çš„å›å¤éƒ½å°†è¢«ç”¨äºè¯­éŸ³åˆæˆï¼Œä»»ä½•éæ–‡æœ¬å­—ç¬¦éƒ½ä¼šå¯¼è‡´åˆæˆå¤±è´¥ã€‚"},
                    {"role": "user", "content": f"{user_input}"},
                ],
            )
            resp_text = completion.choices[0].message.content
            # print(f'å¤§æ¨¡å‹å›å¤ï¼š{resp_text}')
            return resp_text

        except Exception as e:
            print(f"è°ƒç”¨å¤§æ¨¡å‹APIé”™è¯¯: {e}")
            return "æŠ±æ­‰ï¼Œæˆ‘åˆšæ‰æ²¡å¬æ¸…æ¥šï¼Œèƒ½å†è¯´ä¸€æ¬¡å—ï¼Ÿ"

    def run_conversation_cycle(self, user_text=None):
        """è¿è¡Œä¸€æ¬¡å®Œæ•´çš„å¯¹è¯å¾ªç¯"""
        try:
            # 1. å½•éŸ³
            audio_file = self.record_audio()

            # 2. è¯­éŸ³è½¬æ–‡æœ¬
            if audio_file:
                # print("æ­£åœ¨è¯†åˆ«è¯­éŸ³...")
                user_text = self.speech_to_text(audio_file)
            if not user_text:
                user_text = "ä½ å¥½,æˆ‘æ˜¯æçˆ·çˆ·"  # é»˜è®¤é—®å€™

            # print(f"è¯†åˆ«ç»“æœ: {user_text}")

            # # 3. è°ƒç”¨å¤§æ¨¡å‹
            # print("æ­£åœ¨ç”Ÿæˆå›å¤...")
            response_text = self.call_bailian_api(memory_context="", user_input=user_text)
            # print(f"AIå›å¤: {response_text}")

            # 4. æ–‡æœ¬è½¬è¯­éŸ³
            # print("æ­£åœ¨åˆæˆAIè¯­éŸ³...")
            response_audio = self.text_to_speech(response_text)

            # 5. æ’­æ”¾å›å¤
            if response_audio:
                print("æ’­æ”¾å›å¤...")
                self.play_audio(response_audio)

            return True

        except Exception as e:
            print(f"å¯¹è¯å¾ªç¯é”™è¯¯: {e}")
            return False

    def test_audio_system(self):
        """æµ‹è¯•æ•´ä¸ªéŸ³é¢‘ç³»ç»Ÿ"""
        import pyaudio
        import wave

        p = pyaudio.PyAudio()

        print("=== éŸ³é¢‘ç³»ç»Ÿæµ‹è¯• ===")

        # æµ‹è¯•è¾“å…¥è®¾å¤‡
        print("è¾“å…¥è®¾å¤‡:")
        for i in range(p.get_device_count()):
            info = p.get_device_info_by_index(i)
            if info['maxInputChannels'] > 0:
                print(f"  è®¾å¤‡ {i}: {info['name']}")

        # æµ‹è¯•è¾“å‡ºè®¾å¤‡
        print("è¾“å‡ºè®¾å¤‡:")
        for i in range(p.get_device_count()):
            info = p.get_device_info_by_index(i)
            if info['maxOutputChannels'] > 0:
                print(f"  è®¾å¤‡ {i}: {info['name']}")

        p.terminate()

        # æµ‹è¯• wave æ¨¡å—
        print("wave æ¨¡å—æµ‹è¯•...")
        try:
            with wave.open('test.wav', 'w') as wf:
                wf.setnchannels(1)
                wf.setsampwidth(2)
                wf.setframerate(16000)
                wf.writeframes(b'\x00' * 32000)  # 2ç§’é™éŸ³
            print("wave å†™å…¥æµ‹è¯•é€šè¿‡")

            with wave.open('test.wav', 'r') as wf:
                frames = wf.getnframes()
                print(f"è¯»å–æµ‹è¯•: {frames} å¸§")
            print("wave è¯»å–æµ‹è¯•é€šè¿‡")

            import os
            os.remove('test.wav')

        except Exception as e:
            print(f"wave æµ‹è¯•å¤±è´¥: {e}")


class ElderlyCompanionWithMemory(ElderlyCompanionDemo):
    def __init__(self):
        super().__init__()
        # è®°å¿†ç®¡ç†å™¨
        self.memory_manager = MemoryManager()
        # å®æ—¶ç›‘å¬å™¨
        self.realtime_monitor = RealTimeVoiceMonitor(self)
    def call_bailian_api_with_memory(self, user_input):
        """å¸¦é•¿æœŸè®°å¿†çš„å¤§æ¨¡å‹è°ƒç”¨"""
        try:
            # 1. æ£€ç´¢ç›¸å…³è®°å¿†
            related_memories = self.memory_manager.retrieve_related_memories(user_input)

            # 2. æ„å»ºè®°å¿†ä¸Šä¸‹æ–‡
            memory_context = ""
            if related_memories:
                memory_context = "ç›¸å…³è®°å¿†ï¼š\n"
                for memory in related_memories:
                    speaker = "è€äºº" if memory["speaker"] == "user" else "å°ä¼´"
                    memory_context += f"- {speaker}æ›¾è¯´è¿‡ï¼š{memory['content']}\n"
                memory_context += "\n"
            print(f'æ£€ç´¢åˆ°ç›¸å…³è®°å¿†ï¼š{memory_context}')

            # 3. è°ƒç”¨å¤§æ¨¡å‹ï¼ˆä½¿ç”¨APIè°ƒç”¨æ–¹å¼ï¼‰
            response = self.call_bailian_api(memory_context, user_input)  # å¤ç”¨æ‚¨ç°æœ‰çš„æ–¹æ³•

            # 4. å­˜å‚¨å½“å‰å¯¹è¯åˆ°é•¿æœŸè®°å¿†
            self.memory_manager.store_memory(user_input, "user")
            self.memory_manager.store_memory(response, "assistant")

            return response

        except Exception as e:
            print(f"å¸¦è®°å¿†çš„å¯¹è¯é”™è¯¯: {e}")
            return self.call_bailian_api(user_input)  # é™çº§åˆ°æ™®é€šå¯¹è¯

    def run_conversation_cycle_with_memory(self):
        """å¸¦é•¿æœŸè®°å¿†çš„å¯¹è¯å¾ªç¯"""
        try:
            # 1. å½•éŸ³
            audio_file = self.record_audio()

            # 2. è¯­éŸ³è½¬æ–‡æœ¬
            print("æ­£åœ¨è¯†åˆ«è¯­éŸ³...")
            a = time.time()
            user_text = self.speech_to_text(audio_file)
            if not user_text:
                user_text = "ä½ å¥½"
            print(f"æ­£åœ¨è¯†åˆ«è¯­éŸ³è€—æ—¶{time.time()-a}")
            print(f"è¯†åˆ«ç»“æœ: {user_text}")

            # 3. å¸¦è®°å¿†çš„å¤§æ¨¡å‹è°ƒç”¨
            print("æ­£åœ¨ç”Ÿæˆå›å¤ï¼ˆå¸¦è®°å¿†ï¼‰...")
            a = time.time()
            response_text = self.call_bailian_api_with_memory(user_text)
            print(f"æ­£åœ¨ç”Ÿæˆå›å¤ï¼ˆå¸¦è®°å¿†ï¼‰...è€—æ—¶{time.time() - a}")
            print(f"AIå›å¤: {response_text}")

            # 4. æ–‡æœ¬è½¬è¯­éŸ³
            print("æ­£åœ¨åˆæˆè¯­éŸ³...")
            a = time.time()
            response_audio = self.text_to_speech(response_text)
            print(f"æ­£åœ¨åˆæˆè¯­éŸ³...è€—æ—¶{time.time() - a}")
            # 5. æ’­æ”¾å›å¤
            if response_audio:
                print("æ’­æ”¾å›å¤...")
                self.play_audio(response_audio)

            return True

        except Exception as e:
            print(f"å¯¹è¯å¾ªç¯é”™è¯¯: {e}")
            return False

    def show_memory_stats(self):
        """æ˜¾ç¤ºè®°å¿†ç»Ÿè®¡"""
        try:
            # è·å–æ‰€æœ‰è®°å¿†
            all_memories = self.memory_manager.collection.get()
            count = len(all_memories['ids']) if all_memories['ids'] else 0

            print(f"\n=== è®°å¿†ç³»ç»Ÿç»Ÿè®¡ ===")
            print(f"æ€»è®°å¿†æ•°é‡: {count}")

            # æŒ‰åˆ†ç±»ç»Ÿè®¡
            if count > 0:
                categories = {}
                for metadata in all_memories['metadatas']:
                    cat = metadata.get('category', 'unknown')
                    categories[cat] = categories.get(cat, 0) + 1

                for cat, num in categories.items():
                    chinese_name = self.memory_manager.memory_categories.get(cat, cat)
                    print(f"{chinese_name}: {num}æ¡")

            return count

        except Exception as e:
            print(f"ç»Ÿè®¡è®°å¿†é”™è¯¯: {e}")
            return 0

    def search_memories(self, query):
        """æœç´¢ç‰¹å®šè®°å¿†"""
        memories = self.memory_manager.retrieve_related_memories(query, n_results=5)

        print(f"\n=== æœç´¢ '{query}' ç›¸å…³è®°å¿† ===")
        for i, memory in enumerate(memories, 1):
            speaker = "è€äºº" if memory["speaker"] == "user" else "å°ä¼´"
            category = self.memory_manager.memory_categories.get(memory["category"], memory["category"])
            print(f"{i}. [{category}] {speaker}: {memory['content']}")

        return memories

    def start_realtime_companion(self):
        """å¯åŠ¨å®æ—¶é™ªä¼´æ¨¡å¼"""
        print("=" * 60)
        print("è€å¹´é™ªä¼´æœºå™¨äºº - å®æ—¶ç›‘å¬æ¨¡å¼")
        print("=" * 60)
        print("ç‰¹æ€§:")
        print("  â€¢ 24/7æŒç»­ç›‘å¬ç¯å¢ƒ")
        print("  â€¢ æ™ºèƒ½è¯­éŸ³æ´»åŠ¨æ£€æµ‹")
        print("  â€¢ è‡ªåŠ¨å¼€å§‹/ç»“æŸå½•éŸ³")
        print("  â€¢ å®æ—¶å¤„ç†ä¸å“åº”")
        print("  â€¢ 10ç§’ã€30ç§’ã€ç”šè‡³å‡ åˆ†é’Ÿåè¯´è¯éƒ½èƒ½å“åº”")
        print("=" * 60)

        # æ˜¾ç¤ºè®°å¿†ç»Ÿè®¡
        self.show_memory_stats()

        # å¯åŠ¨å®æ—¶ç›‘å¬
        self.realtime_monitor.start_realtime_listening()

    def start_demo(self, memory=True, realtime=False):
        """å¯åŠ¨Demo - å¢åŠ å®æ—¶æ¨¡å¼é€‰é¡¹"""
        if realtime:
            self.start_realtime_companion()
        else:
            # åŸæœ‰çš„å¾ªç¯æ¨¡å¼
            self.start_demo_old(memory)

    def start_demo_old(self, memory=True):
        """å¯åŠ¨Demo"""
        print("=" * 50)
        print("è€å¹´é™ªä¼´æœºå™¨äºº Demo å¯åŠ¨")
        print("æŒ‰ä¸‹ Ctrl+C é€€å‡º")
        print("=" * 50)

        # ä¸»å¾ªç¯
        while True:
            try:
                print("\nè¯·è¯´è¯...")
                if memory:
                    success = self.run_conversation_cycle_with_memory()
                else:
                    success = self.run_conversation_cycle()
                print("\næ­£åœ¨ç­‰å¾…ä¸‹ä¸€æ¬¡å¾ªç¯...")
                time.sleep(1000)
                if not success:
                    print("å¯¹è¯å¤±è´¥ï¼Œé‡æ–°å¼€å§‹...")
                    time.sleep(2)

            except KeyboardInterrupt:
                print("\n\næ„Ÿè°¢ä½¿ç”¨ï¼Œå†è§ï¼")
                break
            except Exception as e:
                print(f"å‘ç”Ÿé”™è¯¯: {e}")
                time.sleep(1)


# è¿è¡ŒDemo
if __name__ == "__main__":
    companion = ElderlyCompanionWithMemory()
    companion.start_demo(memory=True, realtime=True)           # å¸¦è®°å¿†ç‰ˆæœ¬ æ”¯æŒ å®æ—¶ç›‘å¬è¯­éŸ³
    # companion.start_demo_old(memory=True)


